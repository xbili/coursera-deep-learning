{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "Suppose we trained a neural network for image recognition. If we want to transfer what we learned into another task, what we can do is to remove the last output layer of the neural network, and create a new output layer. Then we swap in a new dataset `(X, Y)`, initialize the last layer's weights randomly and retrain neural network on the new dataset.\n",
    "\n",
    "If we have limited data, we can just retrain the last output layer. If we have more data, we can retrain all of the parameters in the neural network.\n",
    "\n",
    "The initial phase of training before replacing the final layer is then called **pre-training**. The second phase of training is called **fine-tuning**.\n",
    "\n",
    "## Why does this work?\n",
    "\n",
    "Low level features can be learned from a very large dataset since it has already learned from the structure of a larger set of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook lays the foundation for the other more advanced optimization algorithms.\n",
    "\n",
    "# Exponentially Weighted Averages\n",
    "\n",
    "The key intuition for exponentially weighted averages is encapsulated by this formula:\n",
    "\n",
    "$$v_t = \\beta \\ v_{t-1} + (1 - \\beta) \\ \\theta_t$$\n",
    "\n",
    "We weight each parameter $\\theta$ in order to get a 'moving average' of the actual value. Suppose that we express the temperature ($v_t$) of a certain area as a function of the current day ($t$).\n",
    "\n",
    "![Temperature](./images/temperature.png)\n",
    "\n",
    "By applying the above formula, we can think of $v_t$ as approximately averaging over $\\frac{1}{1 - \\beta}$ days of temperature at a single point of time, $t$. Below is the curve that we get if we set $\\beta = 0.9$.\n",
    "\n",
    "![Temperature Fit (small beta)](./images/temperature-fit-small.png)\n",
    "\n",
    "What happens if we increase the value of $\\beta$? Say let's increase to $\\beta = 0.98$.\n",
    "\n",
    "![Temperature Fit (large beta)](./images/temperature-fit-large.png)\n",
    "\n",
    "We will get the green curve. Note that the curve is **smoother** but also at the same time it moves towards the **right**.\n",
    "\n",
    "## Intuition\n",
    "\n",
    "The intuition here is similar to the operating concept I've learnt earlier for scheduling (if I recall correctly). If we expand out the term for $v_t$, we observe that each term reflects the **current value** and the **other terms at different $t$**. All the coefficients will add up to $1$.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "The implementation for this is really straightforward, just follow the equations! Remember to initialize $v_0 = 0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Correction\n",
    "\n",
    "There is a slight problem with the implementation of exponentially weighted averages. Refer to the plot below:\n",
    "\n",
    "![Bias Correction](./images/bias-correction.png)\n",
    "\n",
    "The purple line is an addition with $\\beta = 0.98$. We observe that the temperature starts very close to zero. It is easy to observe why this is the case when we take a look at the formula for exponentially weighted averages.\n",
    "\n",
    "Our initial value starts with $0$, therefore $v_1 = 0 + (1 - 0.98) \\ \\theta_t$, which gives us $v_1 = 0.02 \\  \\theta_t$. This results in a very small value in the beginning, requiring the exponentially weighted average to **'warm up'** before the estimate goes back to being more indicative of our training examples.\n",
    "\n",
    "To solve this problem, we apply something known as **bias correction**.\n",
    "\n",
    "After we calculate the value of $v_t$, we perform the following correction update:\n",
    "\n",
    "$$v^{\\text{corrected}}_t := \\frac{v_t}{1 - \\beta^t}$$\n",
    "\n",
    "This helps us reduce the effect of $1 - \\beta$ in our $v_t$ calculation, we divide it by a very small value $< 1$ (same effect as multiplying) to compensate for the small value. As $t$ increases, we observe that $1 - \\beta^t \\approx 1$. The correction operation will not differ too much from the original $v_t$ value.\n",
    "\n",
    "People normally do not implement bias correction, but personally I think it is not something too difficult to implement, so why not? :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

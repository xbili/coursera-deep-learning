{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we explore some other optimization algorithms other than just plain ol' vanilla gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent with Momentum\n",
    "\n",
    "Momentum is a clever concept that allows us to **compute exponentially weighted gradient and use that gradient to update the parameters** instead of our usual `dW` and `db`.\n",
    "\n",
    "Normal gradient descent tend to **oscillate** up and down before reaching the global minima.\n",
    "\n",
    "![Gradient Descent Oscillate](./images/gradient-descent-oscillate.png)\n",
    "\n",
    "Referring the to above diagram, we want to achieve a **large** update on the horizontal axis, but **small** update on the vertical axis. This will allow us to reach the global minima faster.\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "The algorithm makes use of our concept that we just learnt, exponentially weighted average:\n",
    "\n",
    "$$v_t = \\beta v_t + (1 - \\beta) \\theta_5$$\n",
    "\n",
    "But in this case, we set $v_t$ as $v_{\\text{dW}}$ and $\\theta_t$ as $\\text{dW}$.\n",
    "\n",
    "Therefore the algorithm is as follows, we intialize $v_{\\text{dW}} = 0$, and for each iteration $t$:\n",
    "\n",
    "1. Compute `dW`, `db` from our current mini-batch\n",
    "2. $v_{\\text{dW}} := \\beta \\ v_{\\text{dW}} + (1 - \\beta) \\ \\text{dW}$\n",
    "3. $v_{\\text{db}} := \\beta \\ v_{\\text{db}} + (1 - \\beta) \\ \\text{db}$\n",
    "4. $\\text{W} := \\text{W} - \\alpha v_{\\text{dW}}$\n",
    "5. $\\text{b} := \\text{b} - \\alpha v_{\\text{db}}$\n",
    "\n",
    "Stesp 2 and 3 are our calculation of momentum, and steps 4 and 5 are our gradient descent update, but with $v_{\\text{dW}}$ and $v_{\\text{db}}$ instead.\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "$\\alpha$ is still our learning rate hyperparameter which should be tuned. It turns out that $\\beta = 0.9$ works well for most cases and is robust enough to be the default parameter to be applied to any problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSProp (Root Mean Squared Prop)\n",
    "\n",
    "This algorithm is another method used to speed up our gradient descent. The intuition is to penalize the cause of the vertical oscillations, while rewarding the horizontal oscillations (refer to diagram from gradient descent with momentum).\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "The algorithm is as follows, initialize $S_{\\text{dW}} = 0$, and on each iteration $t$:\n",
    "\n",
    "1. Compute `dW`, `db` from our current mini-batch\n",
    "2. $S_{\\text{dW}} := \\beta \\ S_{\\text{dW}} + (1 - \\beta) \\ \\text{dW}^2$\n",
    "3. $S_{\\text{db}} := \\beta \\ S_{\\text{db}} + (1 - \\beta) \\ \\text{db}^2$\n",
    "4. $\\text{W} := \\text{W} - \\alpha \\frac{\\text{dW}}{\\sqrt{S_{\\text{dW}}}}$\n",
    "4. $\\text{b} := \\text{b} - \\alpha \\frac{\\text{db}}{\\sqrt{S_{\\text{db}}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam (Adaptive Moment Estimation)\n",
    "\n",
    "This is the optimization that we should use for almost all kinds of machine learning tasks. It is a **combination of momentum and RMSProp**, and according the the course material, *bias correction is applied here*.\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "The computation for $S$ and $v$ values are the same as above, I will only write in the update step here.\n",
    "\n",
    "$$\\text{W} := \\text{W} - \\alpha \\frac{v^{\\text{corrected}}_{\\text{dW}}}{\\sqrt{S^{\\text{corrected}}_{\\text{dW}}} + \\epsilon}$$\n",
    "$$\\text{b} := \\text{b} - \\alpha \\frac{v^{\\text{corrected}}_{\\text{db}}}{\\sqrt{S^{\\text{corrected}}_{\\text{db}}} + \\epsilon}$$\n",
    "\n",
    "## Hyperparameters\n",
    "\n",
    "To identify between the two hyperparameters $\\beta$ of $S$ and $v$, we call the hyperparamter for $v$ as $\\beta_1$ and hyperparameter of $S$ as $\\beta_2$.\n",
    "\n",
    "The default values are suggested as follows:\n",
    "\n",
    "- $\\alpha$ : (to be tuned)\n",
    "- $\\beta_1$: 0.9 (default)\n",
    "- $\\beta_2$: 0.999 (default)\n",
    "- $\\epsilon$: $10^{-8}$ (not important)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Decay\n",
    "\n",
    "This concept is pretty simple, we just reduce the learning rate as the loss converges. The intuition is that the further we are from the convergence point, the greater the step we can afford to take without missing the convergence point. It's like **golf**, we don't swing hard when we are just one or two meter away from the hole.\n",
    "\n",
    "The decay is applied over **epochs**, reducing the learning rate after each epoch. The more commonly used update rule is:\n",
    "\n",
    "$$\\alpha := \\frac{1}{1 + \\text{decay rate} * \\text{epoch}} \\alpha_0$$\n",
    "\n",
    "There are other kind of decays that we can look up, and we can even perform manual decay if we want to. i.e. observe the optimization algorithm and reduce the learning rate whenever you deem fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note on Local Optimas\n",
    "\n",
    "In GOML, we are always afraid of ending up in a local optima. We like to look at graphs such as those below and tell ourselves that we need to be careful not to feel satisfied when we reach the little small potholes, when the actual minima is a giant well.\n",
    "\n",
    "![Local Optima](./images/local-optima.png)\n",
    "\n",
    "However, in higher dimensions, we find that most of the time we are not dealing with the little small potholes, but rather **saddle points** like the one below.\n",
    "\n",
    "![Saddle Point](./images/saddle-point.png)\n",
    "\n",
    "Why is this not a problem? Because the chances of getting into a local optima is **very small**.\n",
    "\n",
    "![Horsey](./images/horsey.png)\n",
    "\n",
    "I'll just include Andrew's horse because I find that every Professor likes to draw a picture of a horse when trying to explain why it's called a saddle point, and I am very easily amused by their work of art."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From previous courses, we have discovered that there are many different choices to improve the performance of the system. For example, choice of optimizers, network architecture, data size etc.\n",
    "\n",
    "Here we explore how do we efficiently trying out different ideas for our deep learning algorithms. The first concept is **orthogonalization**.\n",
    "\n",
    "# Orthogonalization\n",
    "\n",
    "The most effective machine learning practioners are very clear about what they want to tune in order to get what they want.\n",
    "\n",
    "## Chain of assumptions in ML\n",
    "\n",
    "1. Fit training set well on cost function (close to human level performance)\n",
    "2. Fit dev set well on cost function\n",
    "3. Fit test set well on cost function\n",
    "4. Performs well in real world\n",
    "\n",
    "For each of the criterion above, we will tune a different 'knob' to make the algorithm perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Number Evaluation Metric\n",
    "\n",
    "To be able to effectively evaluate the machine learning algorithm, we have to come up with a single real number evaluation metric at the beginning of the project. i.e. what do we aim to achieve? Then we can get started to work towards it.\n",
    "\n",
    "An example is our classification task with two metrics **precision** and **recall**. With two evaluation metrics, it is difficult to know which to pick. What is recommended is to define a new evaluation metric that combines both metrics. (In this case, the F1-score - the harmonic mean of precision and recall)\n",
    "\n",
    "We can then use this single number to compare between models. This will speed up the iterative process of improving the machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satisficing Metrics\n",
    "\n",
    "It is not easy to combine everything we care about into a single real number. So we split the metric into **satisficing** and **optimizing** metrics.\n",
    "\n",
    "Suppose that we built a cat classifier, and we are concerned with both the accuracy and running time. One metric that we can use is to combine both metrics together in a linear weighted sum.\n",
    "\n",
    "$$\\text{Cost} = \\text{Accuracy}  - 0.5 \\times \\text{Running Time}$$\n",
    "\n",
    "But a linear weighted time metric might not make a lot of sense in this case, what does it mean to add the two values together? Instead we can do something like this:\n",
    "\n",
    "1. Maximize accuracy (Optimizing)\n",
    "2. Subject to running time < 100ms (Satisficing)\n",
    "\n",
    "If we have more than 2 metrics, we can set $N - 1$ metrics as our satisficing metrics, and $1$ optimizing metric."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
